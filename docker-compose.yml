services:
  gpt-sovits:
    image: legwork7623/gpt-sovits:latest 
    container_name: gpt-sovits-container
    environment:
      - is_half=False
      - is_share=False
    volumes:
      - ./output:/workspace/output
      - ./logs:/workspace/logs
      - ./SoVITS_weights:/workspace/SoVITS_weights
      - ./reference:/workspace/reference
    working_dir: /workspace
    ports:
      - "9880:9880"
    shm_size: 16G
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    stdin_open: true
    tty: true
    restart: unless-stopped
  ollama:
    image: ollama/ollama:0.9.0
    container_name: ollama-container
    ports:
      - "11434:11434"
    volumes:
      - ./ollama:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_HOST=0.0.0.0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    tty: true
    entrypoint: ["/bin/ollama", "serve"]
    restart: unless-stopped
  core:
    #image: legwork7623/kurisu-assistant-core:latest
    build:
      context: ./core
      dockerfile: Dockerfile
    container_name: core-container
    ports:
      - "15597:15597"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - TTS_API_URL=http://gpt-sovits-container:9880/tts
      - LLM_API_URL=http://ollama-container:11434
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /usr/bin/docker:/usr/bin/docker:ro
      - ./core/mcp_tools:/app/mcp_tools
      - ./core/whisper-finetuned:/app/whisper-finetuned
      - ./core/configs:/app/configs
    tty: true
    restart: unless-stopped
  
networks:
  default:
